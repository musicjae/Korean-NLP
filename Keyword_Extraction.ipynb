{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keyword_Extraction.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNpYBaSNqBMEQyi6Hxq0woA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musicjae/Korean-NLP/blob/main/Keyword_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fpxRQmzINSC"
      },
      "source": [
        "# Procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-PX7U8TH4tj"
      },
      "source": [
        "- [1] Execute sentiment analysis to use BERT  \r\n",
        "- [2] Extract keywords to use KR-WordRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBf1om8JH2Em",
        "outputId": "e9abfa7a-5a63-4de8-b6d3-a64762aba9d5"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_HZNWxgITTW",
        "outputId": "b5029d45-d2ca-4ebc-e63b-137b54aa34ad"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install krwordrank\r\n",
        "!pip install soynlp\r\n",
        "!pip install konlpy"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: krwordrank in /usr/local/lib/python3.7/dist-packages (1.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from krwordrank) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.18.4 in /usr/local/lib/python3.7/dist-packages (from krwordrank) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from krwordrank) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->krwordrank) (1.0.1)\n",
            "Requirement already satisfied: soynlp in /usr/local/lib/python3.7/dist-packages (0.0.493)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.0.1)\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 319kB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.5MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: JPype1, beautifulsoup4, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJHp3lKCru5f"
      },
      "source": [
        "## import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pOMKTpWIaDu"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import torch\r\n",
        "\r\n",
        "from transformers import BertTokenizer\r\n",
        "from transformers import PreTrainedTokenizer\r\n",
        " \r\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\r\n",
        "from transformers import get_linear_schedule_with_warmup\r\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import copy\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import time\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "from krwordrank.word import KRWordRank\r\n",
        "from krwordrank.hangle import normalize\r\n",
        "from krwordrank.sentence import summarize_with_sentences\r\n",
        "import re\r\n",
        "import konlpy\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep0FJNv6JNzj"
      },
      "source": [
        "# 감성분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGvqy0zdKGOw"
      },
      "source": [
        "#### 장치 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgL7HpOTKHEy",
        "outputId": "612d549d-2cf8-460b-e460-b2bc7d66449b"
      },
      "source": [
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0JO_viiJ3EF"
      },
      "source": [
        "#### 토크나이저 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldeB64l8J2cc"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"beomi/kcbert-base\", do_lower_case=False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGeEhZ9jJ4t8"
      },
      "source": [
        "#### kcbert 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFMMxNglInPK",
        "outputId": "2d0a7ee0-539a-477d-aca2-fbb06fc367f7"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"beomi/kcbert-base\", num_labels=2)\r\n",
        "model.cuda()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(300, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjzXRFNhJbX2",
        "outputId": "1c407ac3-aee8-4607-c6e5-36c2bdddaaf2"
      },
      "source": [
        "def load_model(model, path):\r\n",
        "    model.load_state_dict(torch.load(path))\r\n",
        "\r\n",
        "bert_path = '/content/drive/MyDrive/Colab_Notebooks/JJY/버트 감성 분석/bert_감성분석/bert.pth'\r\n",
        "model.load_state_dict(torch.load(bert_path),strict=False)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEvi3Iv2Jmua"
      },
      "source": [
        "### 실제 예문 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbGr95Z7JoSy"
      },
      "source": [
        "\r\n",
        "# 입력 데이터 변환\r\n",
        "def convert_input_data(sentences):\r\n",
        "\r\n",
        "    # BERT의 토크나이저로 문장을 토큰으로 분리\r\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n",
        "\r\n",
        "    # 입력 토큰의 최대 시퀀스 길이\r\n",
        "    MAX_LEN = 128\r\n",
        "\r\n",
        "    # 토큰을 숫자 인덱스로 변환\r\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "    \r\n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\r\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "    # 어텐션 마스크 초기화\r\n",
        "    attention_masks = []\r\n",
        "\r\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\r\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\r\n",
        "    for seq in input_ids:\r\n",
        "        seq_mask = [float(i>0) for i in seq]\r\n",
        "        attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "    # 데이터를 파이토치의 텐서로 변환\r\n",
        "    inputs = torch.tensor(input_ids)\r\n",
        "    masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "    return inputs, masks\r\n",
        "\r\n",
        "\r\n",
        "def test_sentences(model,sentences):\r\n",
        "\r\n",
        "    # 평가모드로 변경\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # 문장을 입력 데이터로 변환\r\n",
        "    inputs, masks = convert_input_data(sentences)\r\n",
        "\r\n",
        "    # 데이터를 GPU에 넣음\r\n",
        "    b_input_ids = inputs.to(device)\r\n",
        "    b_input_mask = masks.to(device)\r\n",
        "            \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "\r\n",
        "    # 로스 구함\r\n",
        "    logits = outputs[0]\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "\r\n",
        "    return logits"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEV-6PSOJop-"
      },
      "source": [
        "def runrunrun(model,sen,scoreview=None):\r\n",
        "    sen = [sen]\r\n",
        "    score = test_sentences(model,sen)\r\n",
        "    result = np.argmax(score)\r\n",
        "\r\n",
        "    if result == 1:\r\n",
        "        if abs(score[0][1]-score[0][0]) < 0.4:\r\n",
        "            return 2\r\n",
        "        else:\r\n",
        "            return 1\r\n",
        "\r\n",
        "    elif result == 0:\r\n",
        "        if abs(score[0][1]-score[0][0]) < 1.5:\r\n",
        "            return 2\r\n",
        "        else:\r\n",
        "            return 0\r\n",
        "\r\n",
        "    if scoreview == True:\r\n",
        "        print(scoreview)\r\n",
        "    \r\n",
        "num_neutral=0\r\n",
        "num_positive = 0\r\n",
        "num_negative = 0\r\n",
        "pos_texts = []\r\n",
        "neg_texts=[]\r\n",
        "neu_texts = []\r\n",
        "\r\n",
        "news = '/content/drive/MyDrive/Colab_Notebooks/JJY/notes/한국어 nlp/dataset/news.txt'\r\n",
        "news = pd.read_csv(news,delimiter='\\t')\r\n",
        "#print(news.head(2))\r\n",
        "#print(news.columns)\r\n",
        "news = news[['title','header','contents']]\r\n",
        "\r\n",
        "for sen in news.title:\r\n",
        "    sen = sen.replace('[노트펫]','')\r\n",
        "    sen = sen.replace('[에세이]','')\r\n",
        "    sen = sen.replace(r'[^ ㄱ-ㅣ가-힣]+',' ') # 한글을 제외한 나머지 제거\r\n",
        "    sen = re.sub('[-=.#/?:$\\\\}]', '', sen)\r\n",
        "    sen = sen.replace('\\'','')\r\n",
        "    if runrunrun(model,sen) == 1:\r\n",
        "        num_positive += 1\r\n",
        "        pos_texts.append(sen)\r\n",
        "    elif runrunrun(model,sen) == 0:\r\n",
        "        num_negative += 1\r\n",
        "        neg_texts.append(sen)\r\n",
        "    elif runrunrun(model,sen) == 2:\r\n",
        "        num_neutral += 1\r\n",
        "        neu_texts.append(sen)"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "0QKtkp34ecFs",
        "outputId": "054b82cb-71c8-4717-a486-e4e58c586e80"
      },
      "source": [
        "print(f'총 자료 개수:{len(news.title)}\\n')\r\n",
        "x = np.arange(3)\r\n",
        "\r\n",
        "pos_neg = ['positive','neutral','negative']\r\n",
        "values = [num_positive, num_neutral, num_negative]\r\n",
        "\r\n",
        "plt.bar(x, values)\r\n",
        "plt.xticks(x, pos_neg)\r\n",
        "plt.show()"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 자료 개수:45\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LrVQ6Blq4OI",
        "outputId": "d4728cec-699c-471b-f0eb-c6616bd46f8b"
      },
      "source": [
        "pos_texts"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' 냥이에게 하이파이브 요청했다 심쿵한 집사\"머리꿍은 덤이다옹!\"',\n",
              " '혜리, 블랙핑크 로제 반려견 행크와 애틋한 시간\"나 집에 가지마',\n",
              " ' 냥이에게 하이파이브 요청했다 심쿵한 집사\"머리꿍은 덤이다옹!\"',\n",
              " '혜리, 블랙핑크 로제 반려견 행크와 애틋한 시간\"나 집에 가지마',\n",
              " ' 냥이에게 하이파이브 요청했다 심쿵한 집사\"머리꿍은 덤이다옹!\"',\n",
              " '혜리, 블랙핑크 로제 반려견 행크와 애틋한 시간\"나 집에 가지마',\n",
              " ' 냥이에게 하이파이브 요청했다 심쿵한 집사\"머리꿍은 덤이다옹!\"',\n",
              " '혜리, 블랙핑크 로제 반려견 행크와 애틋한 시간\"나 집에 가지마',\n",
              " ' 냥이에게 하이파이브 요청했다 심쿵한 집사\"머리꿍은 덤이다옹!\"',\n",
              " '혜리, 블랙핑크 로제 반려견 행크와 애틋한 시간\"나 집에 가지마']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZXqqlKhrAnb",
        "outputId": "d6a8c16f-bf37-4133-8695-605f4532f387"
      },
      "source": [
        "neu_texts"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['축구 골대 그물에 감겨 의식 잃은 고양이, 심폐소생술로 살려준 소방관들',\n",
              " '쉼터 대신 쓰레기 봉지 집 선택한 노숙인\"강아지들 두고 갈 수 없',\n",
              " '되감기 아님눈 밟기 싫어 자기 발자국 그대로 되짚어 간 똑냥이',\n",
              " '절친 강아지가 무지개다리 건넌 줄 모르고 매일 이웃집 들르는 시바견',\n",
              " '서현, 반려견 뽀뽀 품에 안고 폭풍 애정 표현뽀뽀 쪽\"',\n",
              " '축구 골대 그물에 감겨 의식 잃은 고양이, 심폐소생술로 살려준 소방관들',\n",
              " '쉼터 대신 쓰레기 봉지 집 선택한 노숙인\"강아지들 두고 갈 수 없',\n",
              " '되감기 아님눈 밟기 싫어 자기 발자국 그대로 되짚어 간 똑냥이',\n",
              " '절친 강아지가 무지개다리 건넌 줄 모르고 매일 이웃집 들르는 시바견',\n",
              " '서현, 반려견 뽀뽀 품에 안고 폭풍 애정 표현뽀뽀 쪽\"',\n",
              " '축구 골대 그물에 감겨 의식 잃은 고양이, 심폐소생술로 살려준 소방관들',\n",
              " '쉼터 대신 쓰레기 봉지 집 선택한 노숙인\"강아지들 두고 갈 수 없',\n",
              " '되감기 아님눈 밟기 싫어 자기 발자국 그대로 되짚어 간 똑냥이',\n",
              " '절친 강아지가 무지개다리 건넌 줄 모르고 매일 이웃집 들르는 시바견',\n",
              " '서현, 반려견 뽀뽀 품에 안고 폭풍 애정 표현뽀뽀 쪽\"',\n",
              " '축구 골대 그물에 감겨 의식 잃은 고양이, 심폐소생술로 살려준 소방관들',\n",
              " '쉼터 대신 쓰레기 봉지 집 선택한 노숙인\"강아지들 두고 갈 수 없',\n",
              " '되감기 아님눈 밟기 싫어 자기 발자국 그대로 되짚어 간 똑냥이',\n",
              " '절친 강아지가 무지개다리 건넌 줄 모르고 매일 이웃집 들르는 시바견',\n",
              " '서현, 반려견 뽀뽀 품에 안고 폭풍 애정 표현뽀뽀 쪽\"',\n",
              " '축구 골대 그물에 감겨 의식 잃은 고양이, 심폐소생술로 살려준 소방관들',\n",
              " '쉼터 대신 쓰레기 봉지 집 선택한 노숙인\"강아지들 두고 갈 수 없',\n",
              " '되감기 아님눈 밟기 싫어 자기 발자국 그대로 되짚어 간 똑냥이',\n",
              " '절친 강아지가 무지개다리 건넌 줄 모르고 매일 이웃집 들르는 시바견',\n",
              " '서현, 반려견 뽀뽀 품에 안고 폭풍 애정 표현뽀뽀 쪽\"']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYQ61isCrHbR",
        "outputId": "fc7fe56e-7bee-445f-ac2e-c157c0f19941"
      },
      "source": [
        "neg_texts"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' 장난감 사냥하다 당황한 맹수 꿈나무 고양이 \"오디 갔지\"',\n",
              " ' 아빠 학원 따라갔다 사고 친 강아지강제 공부에 댕무룩',\n",
              " ' 장난감 사냥하다 당황한 맹수 꿈나무 고양이 \"오디 갔지\"',\n",
              " ' 아빠 학원 따라갔다 사고 친 강아지강제 공부에 댕무룩',\n",
              " ' 장난감 사냥하다 당황한 맹수 꿈나무 고양이 \"오디 갔지\"',\n",
              " ' 아빠 학원 따라갔다 사고 친 강아지강제 공부에 댕무룩',\n",
              " ' 장난감 사냥하다 당황한 맹수 꿈나무 고양이 \"오디 갔지\"',\n",
              " ' 아빠 학원 따라갔다 사고 친 강아지강제 공부에 댕무룩',\n",
              " ' 장난감 사냥하다 당황한 맹수 꿈나무 고양이 \"오디 갔지\"',\n",
              " ' 아빠 학원 따라갔다 사고 친 강아지강제 공부에 댕무룩']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "howbu4VvKOIB"
      },
      "source": [
        "# 키워드 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_7ZiPk1rs5x",
        "outputId": "a5aa3fea-7dcd-4059-8435-f3123a719656"
      },
      "source": [
        "tok = konlpy.tag.Okt()\r\n",
        "\r\n",
        "sen = \"\"\"\r\n",
        "대검찰청 과거사 진상조사단에 소속돼 ‘김학의 사건’을 조사했던 박준영 변호사가 “김학의 전 법무부 차관 사건으로 현실을 무시하며, 졸속으로 진행되는 이 개혁 아닌 (검찰)개혁에 대해 하나하나 설명하며 문제를 제기하겠다”고 밝혔다.\r\n",
        "\r\n",
        "박 변호사는 2일 자신의 페이스북에 올린 ‘난전(難戰) 준비’란 제목의 글에서 ‘김학의 사건’을 공론화할 예정이라고 적었다. 그는 “김 전 차관 사건을 가지고 개혁을 이야기하는 그들을 상대로 김 전 차관 사건으로 반박을 해보겠다”고 말했다. 박 변호사는 2018년 2월부터 이듬해 3월까지 대검 진상조사단에서 ‘김 전 차관 별장 성접대 의혹 사건’을 조사했다.\r\n",
        "\r\n",
        "박 변호사는 ‘김학의 사건’의 공론화 원칙과 방식에 대해 “총장을 죽이려고, 불리한 수사를 그만 두게끔 하려고 1000페이지가 넘는 김 전 차관 보고서를 언론에 흘린 그들과 (내가) 똑같을 순 없다”며 “정치적이라는 오해를 받지 않도록 공익적 목적을 점검하고 또 점검하겠다”고 말했다.\r\n",
        "\r\n",
        "그는 “별장 동영상이 어떻게 세상 밖에 나오게 됐는지 그리고 이를 이용해 돈을 뜯어내려는 과정에서 벌어진 추악한 일들은 드러내지 않고, 동영상 속 남성을 김 전 차관으로 추정했음에도 이를 불기소 이유에 담지 않은 이유에 대한 검사들 의견도 외면하며 사건을 이야기할 수 없다\"고도 주장했다.\r\n",
        "\r\n",
        "박 변호사는 윤석열 검찰총장도 건설업자 윤중천씨 접대 리스트에 있었다는 의혹을 제기한 한 언론 보도를 언급하며 “보고서를 근거로 단독 보도가 정당하다는 주장을 이어갔으면서 정작 보고서에 담긴 다른 문제점과 모순에는 침묵했던 언론에 대해서도 비판해야 한다\"고 지적하기도 했다.\r\n",
        "\"\"\"\r\n",
        "word_list = []\r\n",
        "\r\n",
        "for word in sen.split(sep='\\n'):\r\n",
        "    word = tok.pos(word)\r\n",
        "    if len(word) != 0:\r\n",
        "        for i in range(len(word)):\r\n",
        "\r\n",
        "            if word[i][1] == 'Noun':\r\n",
        "                word_list.append(word[i][0])\r\n",
        "print(word_list)\r\n"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['대검찰청', '과거', '사', '진상', '사단', '소속', '김학의', '사건', '조사', '박준영', '변호사', '김학의', '전', '법무부', '차관', '사건', '현실', '무시', '졸속', '진행', '이', '개혁', '검찰', '개혁', '대해', '하나', '하나', '설명', '문제', '제기', '고', '박', '변호사', '자신', '페이스북', '난전', '준비', '란', '제목', '글', '김학의', '사건', '공론', '예정', '그', '김', '전', '차관', '사건', '가지', '개혁', '이야기', '그', '상대로', '김', '전', '차관', '사건', '반박', '고', '말', '박', '변호사', '이듬해', '대검', '진상', '사단', '김', '전', '차관', '별장', '접대', '의혹', '사건', '조사', '박', '변호사', '김학의', '사건', '의', '공론', '원칙', '방식', '대해', '총장', '수사', '페이지', '김', '전', '차관', '보고서', '언론', '그', '내', '순', '며', '정치', '오해', '공익', '목적', '점검', '또', '점검', '고', '말', '그', '별장', '동영상', '세상', '이용', '돈', '과정', '일', '동영상', '속', '남성', '김', '전', '차관', '추정', '불기소', '이유', '이유', '대한', '검사', '의견', '외면', '사건', '이야기', '수', '고도', '주장', '박', '변호사', '윤석열', '검찰총장', '건설업', '윤중천', '접대', '리스트', '의혹', '제기', '언론', '보도', '언급', '보고서', '근거', '단독', '보도', '주장', '정작', '보고서', '다른', '문제점', '모순', '침묵', '언론', '대해', '서도', '비판', '고', '지적']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dvHI_Yue3t8",
        "outputId": "1f2beeb1-5674-409c-ae40-48729796824b"
      },
      "source": [
        "texts = news.contents\r\n",
        "texts = [normalize(text,english=False,number=True) for text in texts]\r\n",
        "\r\n",
        "stopword= {'지영','있는','있다','지난','모습이','피망이','씨는','라고','비루는'}\r\n",
        "\r\n",
        "keywords,sents = summarize_with_sentences(\r\n",
        "    pos_texts,\r\n",
        "    stopwords = stopword,\r\n",
        "    diversity=0.5,\r\n",
        "    num_keywords=10,\r\n",
        "    num_keysents=10,\r\n",
        "    verbose=True\r\n",
        ")\r\n",
        "\r\n",
        "word_list = []\r\n",
        "\r\n",
        "for word,r in sorted(keywords.items(), key=lambda x:x[1], reverse=True)[:30]:\r\n",
        "    word = tok.pos(word)\r\n",
        "    if len(word) != 0:\r\n",
        "        for i in range(len(word)):\r\n",
        "\r\n",
        "            if word[i][1] == 'Noun':\r\n",
        "                word_list.append('#'+word[i][0])\r\n",
        "print(word_list)"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scan vocabs ... \n",
            "num vocabs = 95\n",
            "done\n",
            "['#냥', '#덤', '#옹', '#집사', '#머리', '#꿍', '#하이파이브', '#요청', '#집', '#로제', '#혜리']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9cL5yyEw7ee",
        "outputId": "2f51f0f7-0863-40fd-8bc8-95f72321a802"
      },
      "source": [
        "wordrank_extractor = KRWordRank(\r\n",
        "    min_count=2,\r\n",
        "    max_length=10,\r\n",
        "    verbose=True\r\n",
        ")\r\n",
        "\r\n",
        "beta = 0.85\r\n",
        "max_iter=10\r\n",
        "\r\n",
        "keywords,rank,graph = wordrank_extractor.extract(texts,beta,max_iter)\r\n",
        "\r\n",
        "\r\n",
        "word_list = []\r\n",
        "\r\n",
        "for word,r in sorted(keywords.items(), key=lambda x:x[1], reverse=True)[:30]:\r\n",
        "    word = tok.pos(word)\r\n",
        "    if len(word) != 0:\r\n",
        "        for i in range(len(word)):\r\n",
        "\r\n",
        "            if word[i][1] == 'Noun':\r\n",
        "                word_list.append('#'+word[i][0])\r\n",
        "print(word_list)\r\n"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scan vocabs ... \n",
            "num vocabs = 3374\n",
            "done\n",
            "['#고양이', '#사진', '#지영', '#피망', '#노트', '#펫', '#지난', '#모습', '#구름', '#씨', '#비루', '#하이파이브', '#보호', '#반려견', '#멤버', '#그녀', '#집사', '#녀석', '#엄마', '#출동', '#뽀뽀', '#콜레']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}